# Project Overview

This project, MAPF-GPT, focuses on utilizing a GPT-like model for Multi-Agent Pathfinding (MAPF). It's a research initiative that combines imitation learning with large-scale pathfinding. The core idea is to train a transformer model on expert solutions generated by the LaCAM solver to learn effective pathfinding strategies.

## Key Technologies

*   **Primary Language:** Python
*   **Machine Learning:** PyTorch
*   **Expert Solver:** LaCAM (C++)
*   **Environment Management:** Docker, `uv`

## Project Structure

The repository is organized as follows:

*   `gpt/`: Contains the PyTorch implementation of the GPT model, including configuration files for different model sizes (`2M`, `6M`, `85M`), the model architecture (`model.py`), and inference logic.
*   `lacam/`: Includes the C++ source code for the LaCAM solver, which is used to generate the expert dataset for training the GPT model.
*   `dataset_configs/`: Configuration files for generating training and validation datasets.
*   `eval_configs/`: Configuration files for evaluating the model on benchmark scenarios.
*   `docker/`: Dockerfile and `requirements.txt` for creating a reproducible environment.
*   `pogema_toolbox/`: Vendored source of pogema-toolbox v0.1.0, included directly for local modification.
*   `moving_ai_tiles/`: Companion module vendored alongside pogema-toolbox.
*   Root-level Python scripts for key operations:
    *   `example.py`: Demonstrates how to run the MAPF-GPT model.
    *   `benchmark.py`: Runs the model evaluation on the POGEMA benchmark.
    *   `generate_dataset.py`: Generates the training dataset using the LaCAM solver.
    *   `download_dataset.py`: Downloads the pre-generated dataset from Hugging Face.
    *   `train.py`: Initiates the training process for the MAPF-GPT model.
    *   `create_env.py`: Script to create the learning environment.

# Building and Running

## Local Installation

It is recommended to use `uv` for local setup.

```bash
uv venv --python 3.10
source .venv/bin/activate
uv pip install -r docker/requirements.txt
```

## Docker Installation

For a more isolated and consistent environment, Docker can be used.

```bash
cd docker
sh build.sh
```

## Running the Model

### Example

To run a simple example with the MAPF-GPT-2M model:

```bash
python example.py --map_name validation-mazes-seed-000 --model 2M --num_agents 32
```

### Evaluation

To evaluate all models on the POGEMA benchmark:

```bash
python benchmark.py
```

### Training

To train the MAPF-GPT-6M model on a single GPU:

```bash
torchrun --standalone --nproc_per_node=1 train.py gpt/config-6M.py
```

# Development Conventions

*   **Model Architecture:** The core model is a GPT-style transformer, as defined in `gpt/model.py`.
*   **Dataset Generation:** Expert trajectories for imitation learning are generated using the LaCAM solver.
*   **Configuration:** Model and training parameters are managed through Python-based configuration files in the `gpt/` directory.
*   **Dependencies:** Python dependencies are listed in `docker/requirements.txt`.
